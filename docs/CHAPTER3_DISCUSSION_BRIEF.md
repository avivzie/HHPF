# Chapter 3: Discussion & Conclusions — Gemini Briefing Document

**Purpose:** This document is a comprehensive brief for writing Chapter 3 of the HHPF thesis. Use it with Gemini (or another LLM) to produce the full Discussion & Conclusions chapter. It addresses: (1) conclusions and examination of findings in relation to research objectives and questions; (2) discussion of relationships between objectives and results and coherence/contradiction with the literature; (3) significance of findings and conclusions; (4) comparison of the developed model with other existing models; (5) improvements and adjustments to maximize efficiency; (6) before-and-after comparison where applicable.

**Do not edit this file for thesis style only** — use it as source material to generate the actual chapter text in your thesis document.

---

## 1. Project Context (Preamble for Chapter 3)

### What the project is
- **Name:** Hybrid Hallucination Prediction Framework (HHPF)
- **Type:** Master's thesis in Computer Science
- **Core objective:** Proactive hallucination prediction for Large Language Models (LLMs) by analyzing internal model signals and prompt characteristics to compute real-time hallucination risk scores.
- **Main research question:** "Which features in the user query and the required knowledge structure are most significantly correlated with the occurrence of hallucinations?"
- **Approach:** Shift from **reactive** (post-hoc) detection to **proactive** prediction using:
  - **Epistemic uncertainty:** Semantic Entropy and Semantic Energy from model internals
  - **Contextual features:** Knowledge Popularity (entity rarity) and Prompt Complexity (lexical, syntactic, question type)
  - **Domain patterns:** Cross-domain hallucination behavior across 5 domains

### Model and data
- **Classifier:** XGBoost binary classifier (gradient boosted decision trees), conservative hyperparameters (max_depth=3, regularization) to prevent overfitting.
- **LLM used for generation:** Llama-3.1-8B-Instruct (via Groq/Together AI). Each prompt gets 5 stochastic samples (temperature 0.7–1.0) for semantic clustering.
- **Domains and samples:** 5 domains, 2,542 samples total: Math (GSM8K, 542), IS Agents (HalluMix, 500), Psychology (TruthfulQA, 500), Medicine (Med-HALT, 500), Finance (TAT-QA, 500).
- **Training:** Per-domain models (no cross-domain leakage); 80/20 stratified train/test; 5-fold stratified CV for robustness; fixed random_state=42.

### What Chapter 3 should accomplish
- **Conclusions:** Examine findings in relation to the research objectives and questions; state clearly what was supported, partially supported, or not supported, and why.
- **Discussion:** Relate objectives to results; compare findings with the literature (coherence vs. contradiction); discuss significance of findings and conclusions.
- **Model comparison:** Compare HHPF with other existing approaches (semantic uncertainty, naive confidence, reactive detection) — advantages and disadvantages.
- **Improvement and adjustment:** Propose concrete improvements and adjustments to bring the model to maximum efficiency, based on the examination and comparison.
- **Before-and-after:** Where applicable (e.g., baseline → full model, methodological changes), present before-and-after comparison to measure efficiency or rigor.

---

## 2. Research Objectives & Questions Recap

| ID | Question | Hypothesis / Intent |
|----|----------|----------------------|
| **RQ1** | Do hybrid features (semantic uncertainty + contextual) outperform baseline approaches? | Hybrid features outperform naive confidence, semantic-only, and context-only baselines. |
| **RQ2** | Does Semantic Entropy (meaning-based uncertainty) provide more reliable hallucination detection than naive confidence metrics (MaxProb, Perplexity)? | Semantic uncertainty outperforms naive confidence metrics. |
| **RQ3** | Do hallucination signatures differ significantly across domains? | Yes — requiring domain-specific or domain-adaptive detection. |
| **RQ3a** | Do hallucination *rates* differ across domains? | Tested via chi-square. |
| **RQ3b** | Does detection performance (AUROC) vary across domains? | Variance in full-model AUROC across domains. |
| **RQ3c** | Do feature *importance* patterns vary across domains? | Coefficient of variation (CV) of feature importance across domains. |

**Baseline and ablations (per domain):** Naive-Only (4 features) → Context-Only → Semantic-Only → Semantic+Context → Full (41–48 features). Same XGBoost config for fair comparison.

---

## 3. Findings in Relation to Research Objectives and Literature

### 3.1 RQ1: Hybrid features vs. baselines

**Finding (examination of results):**
- **Semantic+Context AUROC:** 0.678 ± 0.055  
- **Naive-Only AUROC:** 0.562 ± 0.097  
- **Mean improvement:** +0.116 AUROC (+20.7%)  
- **95% CI (mean improvement):** [-0.027, 0.259]  
- **Raw p-value (paired t-test, two-tailed, n=5 domains):** 0.087  
- **After multiple comparison correction (Bonferroni over 3 primary tests):** p = 0.262 (not significant at α = 0.05)  
- **Effect size:** Cohen's d = 1.007 (large)

**Per-domain:** Hybrid wins in 4/5 domains (Math +0.262, Psychology +0.167, Medicine +0.155, Finance +0.013). **IS Agents:** slight loss (-0.015), where naive features were unusually effective.

**Relationship to objectives:** The objective was to test whether hybrid features outperform baselines. The **direction and magnitude** support the objective (large practical effect, consistent in 4/5 domains). **Statistical conclusion:** partial support — effect is large and consistent but does not survive strict multiple comparison correction; with more domains, significance would likely be reached.

**Literature (coherence/contradiction):**
- **Farquhar et al. (2024)** emphasize linguistic/semantic uncertainty over raw model confidence for reliable uncertainty quantification. **Coherence:** HHPF’s hybrid (semantic + context) improving over naive confidence aligns with that emphasis. **Nuance:** We add contextual features on top of semantic uncertainty and show that the **combination** is what gives the gain; semantic-only (RQ2) is not sufficient alone.
- **Conclusion for Chapter 3:** Coherence with the literature on the value of semantic uncertainty; our contribution is showing that **combining** it with contextual features yields a large practical improvement, with borderline statistical significance under conservative correction.

---

### 3.2 RQ2: Semantic uncertainty vs. naive confidence

**Finding (examination of results):**
- **Semantic-Only AUROC:** 0.605 ± 0.076  
- **Naive-Only AUROC:** 0.562 ± 0.097  
- **Mean improvement:** +0.043 AUROC (+7.7%)  
- **95% CI:** [-0.129, 0.216]  
- **One-tailed p-value (Semantic > Naive):** 0.262 (not significant)  
- **Effect size:** Cohen's d = 0.312 (small–medium)

**Per-domain:** Semantic wins in 4/5 domains (Math +0.222, Psychology +0.067, Medicine +0.073, Finance +0.021). **IS Agents:** strong negative (-0.165) — naive confidence much better.

**Relationship to objectives:** The objective was to test whether Semantic Entropy *outperforms* naive confidence. **Result:** Not supported statistically; semantic-only is insufficient for reliable detection across domains.

**Literature (coherence/contradiction):**
- **Kuhn et al. (2023)** and related work on semantic uncertainty suggest that meaning-based uncertainty can outperform token-level confidence. **Partial contradiction:** In our setup, semantic-only does not reliably outperform naive confidence (p = 0.262), and in one domain (IS Agents) naive confidence is clearly better. **Possible reasons:** (1) API limitation — we lack full logprobs for some samples, so our “naive” baseline may be weaker than in papers that use full access; (2) domain-specificity — in high–hallucination-rate, document-grounded QA (IS Agents), token-level confidence may be more informative; (3) semantic entropy needs to be **combined** with other features (as in RQ1) to show clear benefit.
- **Conclusion for Chapter 3:** No contradiction with the *utility* of semantic uncertainty (it helps when combined); contradiction or nuance is on the claim that semantic uncertainty **alone** consistently outperforms naive confidence — in our multi-domain setting it does not. Discussion should stress “semantic features are necessary but not sufficient” and the IS Agents anomaly as a domain-specific finding.

---

### 3.3 RQ3: Cross-domain variance

**RQ3a — Hallucination rate differences:**  
- Chi-square = 614.64, p < 0.001 (remains highly significant after Bonferroni/FDR).  
- Rates: Psychology 25.0%, Math 29.0%, Medicine 49.6%, Finance 73.8%, IS Agents 87.8%. **Range 3.5×.**

**RQ3b — Domain AUROC variance:**  
- Full-model AUROC by domain: Math 0.797, IS Agents 0.703, Psychology 0.671, Finance 0.632, Medicine 0.619.  
- Mean 0.684 ± 0.071; range 0.178; coefficient of variation 0.104.

**RQ3c — Feature importance variability:**  
- 41 features analyzed. High-variance (CV > 0.3): 26 (63%) — domain-specific. Low-variance (CV < 0.2): 12 (29%) — universal.  
- Top domain-specific (high CV): e.g. entity_type_EVENT, num_semantic_clusters, qtype_where, avg_cluster_size, max_entity_rarity, semantic_entropy (CV 1.137).  
- Universal: naive confidence (MaxProb, Perplexity), basic lexical (lexical diversity, token count), syntactic (parse depth, clause count).

**Relationship to objectives:** Objective was to test whether hallucination signatures differ across domains. **Strongly supported** by rates (RQ3a), AUROC variance (RQ3b), and feature importance variance (RQ3c).

**Literature (coherence):** Growing literature on domain-specificity of LLM failures and the need for domain-adaptive evaluation. **Coherence:** Our results support the need for domain-aware (and possibly domain-adaptive) detection rather than a single one-size-fits-all system.

---

## 4. Significance of Findings and Conclusions

- **First systematic cross-domain ablation** for proactive hallucination prediction with per-domain training, no cross-domain leakage, and proper statistical tests (paired t-tests, chi-square, multiple comparison correction, effect sizes).
- **Practical efficiency:** Full model adds only +0.007 AUROC over Semantic+Context — so **Semantic+Context is a good efficiency/parsimony choice** (fewer features, similar performance).
- **Universal vs. domain-specific features:** 29% of features are stable across domains (universal); 63% are domain-specific. Implication: a core of shared features can be used everywhere; the rest should be adapted or weighted by domain.
- **Domain ordering (by full-model AUROC):** Math (easiest) > IS Agents > Psychology > Finance > Medicine (hardest). Interpretation: deterministic, well-structured tasks (Math) and very high hallucination rate (IS Agents) are more predictable; complex knowledge (Medicine) and document-grounded reasoning (Finance) are harder.
- **Calibration:** Medicine has best ECE (0.057); Psychology has worst (0.344). So good discrimination need not imply good calibration — report both.
- **Conclusions to state explicitly:**
  - RQ1: Hybrid features show a **large practical effect** over naive baselines and are consistent in 4/5 domains; statistical significance is borderline after correction; more domains would likely confirm significance.
  - RQ2: Semantic uncertainty **alone** does not reliably outperform naive confidence; it is **necessary but not sufficient** — combination with contextual (and optionally naive) features is needed.
  - RQ3: Hallucination patterns **strongly differ** across domains (rates, AUROC, feature importance); domain-adaptive or domain-specific approaches are justified.

---

## 5. Comparison with Other Models / Approaches

Compare the developed model (HHPF) with existing approaches so the thesis clearly states advantages and disadvantages.

### 5.1 Semantic Entropy (e.g. Farquhar et al., 2024)

- **Their approach:** Meaning-based (semantic) uncertainty, e.g. via clustering of responses.  
- **HHPF:** Uses semantic entropy (NLI-based clustering with DeBERTa-v3-large) **plus** contextual features (entity rarity, prompt complexity) and optional naive features.  
- **Advantages of HHPF:** (1) Combines semantic with context → +0.116 AUROC over naive in 4/5 domains. (2) Explicit modeling of prompt and knowledge structure. (3) Per-domain training justified by RQ3.  
- **Disadvantages:** More complex pipeline (NLI model, entity extraction, syntactic features); higher latency and compute than pure semantic-entropy methods.

### 5.2 Naive confidence / perplexity baselines

- **Their approach:** MaxProb, perplexity, mean logprob only.  
- **Finding:** Naive-Only AUROC 0.562 ± **0.097** (high variance across domains). Semantic+Context 0.678 ± **0.055** (lower variance).  
- **Advantages of HHPF:** Better mean performance and **more stable** across domains; works even when logprobs are missing or partial (API-agnostic for some features).  
- **Disadvantages of HHPF:** Requires multiple samples and NLI for semantic entropy; more expensive than single-pass confidence.

### 5.3 Reactive (post-hoc) detection

- **Their approach:** Detect hallucination after the full response is generated.  
- **HHPF:** Proactive — risk score can be computed from prompt + (optional) partial response, enabling real-time use (e.g. routing, warnings).  
- **Advantage of HHPF:** Proactive use case; no need to wait for full generation.  
- **Disadvantage:** We do not compare empirically to a specific reactive detector in this thesis; comparison is conceptual.

### 5.4 Domain-specific vs. domain-agnostic

- **Domain-agnostic:** One model for all domains.  
- **HHPF:** One model per domain (no cross-domain training).  
- **Advantage of HHPF:** RQ3 shows strong domain variance (rates, AUROC, feature importance) — per-domain training is justified and gives better control.  
- **Disadvantage:** Need labeled data and training per domain; more models to maintain.

### 5.5 Summary table (for Chapter 3)

| Approach | HHPF advantage | HHPF disadvantage |
|---------|-----------------|-------------------|
| Semantic entropy only | Hybrid (semantic+context) improves over naive; more stable across domains | Heavier pipeline (NLI, context features) |
| Naive confidence only | Higher mean AUROC, lower variance; can work without full logprobs | Needs multiple samples + NLI; higher cost |
| Reactive detection | Proactive risk scoring before full generation | No direct empirical comparison to reactive in this work |
| Domain-agnostic | Per-domain training matches domain variance (RQ3) | Requires per-domain data and training |

---

## 6. Before-and-After Comparison (Efficiency / Rigor)

Use this to show how the model or methodology was improved and how efficiency/rigor was measured.

### 6.1 Model performance: Baseline → Full hybrid

- **Before (Naive-Only baseline):** Mean AUROC 0.562 ± 0.097 across 5 domains.  
- **After (Full model):** Mean AUROC 0.685 ± 0.071.  
- **Improvement:** +0.123 AUROC (+21.9%).  
- **Per-domain examples:** Math 0.500 → 0.797; Psychology 0.514 → 0.671; Medicine 0.473 → 0.619.  
- **Efficiency note:** Semantic+Context (0.678 ± 0.055) is almost as good as Full (+0.007) with fewer features — “before vs after” can also be framed as Naive-Only vs Semantic+Context for a simpler deployment.

### 6.2 Methodological improvements (in response to instructor feedback)

These are before-and-after **methodology** changes that increase rigor and trust in the numbers:

| Aspect | Before | After | How efficiency/rigor is measured |
|--------|--------|-------|-----------------------------------|
| **Cross-validation** | Single train/test split | 5-fold stratified CV on full dataset | CV means ± std reported; single-split and CV conclusions align (e.g. RQ1 p ≈ 0.076 with CV). |
| **Statistical reporting** | p-value only, “borderline significance” | 95% CIs, raw and corrected p-values (Bonferroni, FDR), effect sizes (Cohen’s d) | Precision of estimates and multiple-testing controlled; honest “large effect but not significant after correction” for RQ1. |
| **Imbalanced domains** | AUROC only | AUPRC + PR curves + optimal F1 threshold per domain | Better reflection of performance in imbalanced domains (e.g. Psychology, Math). |
| **AUROC consistency** | Different values in RQ3b vs ROC figures | Single pipeline; all figures and tables use same metrics source (e.g. `metrics_{domain}.json`) | One set of numbers (e.g. Math 0.797, Psychology 0.671) everywhere. |

**Suggested wording for thesis:** “Following feedback, we added 5-fold stratified cross-validation, confidence intervals and multiple comparison corrections, and AUPRC/PR curves for imbalanced domains. We also aligned all reported AUROCs to a single training and evaluation pipeline. These changes do not alter the direction of conclusions but strengthen the rigor and interpretability of the results.”

---

## 7. Improvement and Adjustment Directions

Based on the examination and comparison, the following improvements and adjustments can bring the model and evaluation to maximum efficiency and impact.

### 7.1 Statistical power and generalizability

- **Expand domains:** Current n = 5 domains limits power for RQ1/RQ2 (e.g. RQ1 p = 0.087). Adding 3–5 more domains (e.g. History, Law, CS, Biology, Economics) could make the hybrid effect statistically significant after correction.
- **Larger samples per domain:** Where possible, increase n per domain to stabilize AUROC and feature importance estimates.

### 7.2 Model and training

- **Domain-specific hyperparameter tuning:** Optuna is already used; run it per domain (e.g. different max_depth, learning_rate) to see if AUROC improves, especially for Medicine and Finance.
- **Ensemble:** Train a “universal” model (e.g. on pooled data or shared features) and combine with domain-specific models (e.g. weighted by domain or confidence).
- **Neural classifier:** Compare XGBoost with a transformer-based or other neural classifier on the same features to see if non-linear interactions improve discrimination.

### 7.3 Features and pipeline

- **Domain-specific features:** Add features tailored to hard domains (e.g. Medicine: more medical entity types; Finance: table structure, numeric reasoning cues).
- **Logprobs:** Where API allows, include full logprob-based features to strengthen the naive baseline and re-test RQ2.
- **Semantic entropy efficiency:** Lighter NLI model or fewer samples per prompt to reduce latency while monitoring AUROC.

### 7.4 Understanding anomalies

- **IS Agents:** Investigate why naive confidence outperforms semantic-only (e.g. document-grounded QA, very high hallucination rate 87.8%) and whether a hybrid still helps after domain-specific tuning.
- **Medicine:** Lowest AUROC (0.619) despite best calibration — investigate whether domain-specific features or different labeling (e.g. partial credit) could help.

### 7.5 Evaluation and deployment

- **Threshold and cost-sensitive learning:** Optimize decision threshold (or use cost-sensitive loss) per domain for precision/recall/F1 depending on application.
- **Real-time deployment:** Measure end-to-end latency (feature extraction + XGBoost); consider caching NLI and reusing semantic features for similar prompts.
- **Other LLMs:** Re-run pipeline with another LLM (e.g. GPT-4, Claude, Gemini) to test whether findings generalize beyond Llama-3.1-8B.

---

## 8. Tables and Figures to Reference in Chapter 3

Use these so the written chapter can refer to the same numbers and figures as the rest of the thesis.

### 8.1 Key result tables (source: `outputs/results/5_DOMAIN_FINAL_SUMMARY.md`, `outputs/research_questions/RESULTS_SUMMARY.md`)

- **Full model performance by domain:** AUROC, Accuracy, Precision, Recall, F1, ECE, Hall. rate (Table in 5_DOMAIN_FINAL_SUMMARY).
- **RQ1 per-domain breakdown:** Semantic+Context vs Naive-Only AUROC and Δ per domain.
- **RQ2 per-domain breakdown:** Semantic-Only vs Naive-Only AUROC and Δ per domain.
- **RQ3a:** Hallucination counts and rates by domain with 95% CIs.
- **RQ3b:** Full-model AUROC by domain (ranked).
- **RQ3c:** List of high-CV (domain-specific) and low-CV (universal) features.
- **Ablation summary:** Feature subset (Full, Semantic+Context, Semantic-Only, Context-Only, Naive-Only) vs mean AUROC ± std and improvement over baseline.
- **Statistical test summary:** RQ1/RQ2/RQ3a test type, statistic, raw and corrected p-values, 95% CI, effect size, and conclusion.

### 8.2 Figures (paths under `outputs/`)

- **RQ1:** `research_questions/figures/rq1_ablation_comparison.pdf` (or .png) — feature subset comparison (e.g. bar chart with error bars).
- **RQ2:** `research_questions/figures/rq2_semantic_vs_naive.pdf` — Semantic vs Naive comparison.
- **RQ3a:** `research_questions/figures/rq3a_hallucination_rates.pdf` — hallucination rate distribution by domain.
- **RQ3b:** `research_questions/figures/rq3b_domain_auroc.pdf` — domain-specific AUROC (e.g. bar chart with mean line).
- **RQ3c:** `research_questions/figures/rq3c_feature_importance_heatmap.pdf` — feature importance heatmap (e.g. features × domains).
- **Per-domain (optional):** For imbalanced domains, PR curves and F1 vs threshold: `figures/{domain}/pr_curve_{domain}.pdf` (Psychology, Math, etc.). ROC curves: `figures/{domain}/roc_curve_{domain}.pdf`.

### 8.3 Consistent AUROC values to use everywhere

| Domain     | AUROC  |
|-----------|--------|
| Math      | 0.797  |
| IS Agents | 0.703  |
| Psychology| 0.671  |
| Finance   | 0.632  |
| Medicine  | 0.619  |
| **Mean ± SD** | **0.684 ± 0.071** |

(Source: single training and figure pipeline; see `outputs/results/CONSISTENCY_IMPLEMENTATION_SUMMARY.md` and `FEEDBACK_CHANGES_AND_DRAFT_UPDATE.md`.)

---

## 9. Checklist for the Generated Chapter 3

When generating the actual chapter from this brief, ensure it:

- [ ] States conclusions for RQ1, RQ2, RQ3 (and sub-questions) clearly (supported / partially supported / not supported) with reference to the reported statistics.
- [ ] Discusses the **relationship** between research objectives and results (what the results mean for each objective).
- [ ] Compares findings with the literature (Farquhar et al., Kuhn et al., semantic vs naive, domain-specificity) and states where there is coherence and where there is contradiction or nuance.
- [ ] Explains the **significance** of the findings (first cross-domain ablation, efficiency of Semantic+Context, universal vs domain-specific features, domain ordering).
- [ ] Includes a **comparison of HHPF with other models/approaches** (semantic entropy, naive confidence, reactive detection, domain-agnostic) with advantages and disadvantages.
- [ ] Proposes **improvements and adjustments** (more domains, tuning, ensemble, neural classifier, domain-specific features, IS Agents/Medicine investigation, deployment).
- [ ] Includes **before-and-after** comparison: (1) Naive-Only → Full (and optionally Semantic+Context) for model efficiency; (2) methodological improvements (CV, CIs, multiple comparison correction, AUPRC/PR, AUROC consistency) for rigor.
- [ ] References the **tables and figures** listed in Section 8 and uses the **consistent AUROC values** in Section 8.3.

---

**End of briefing document.** Use this as the main input for drafting Chapter 3 (Discussion & Conclusions) in the thesis.
