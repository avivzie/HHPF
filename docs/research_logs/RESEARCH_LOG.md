# Research Log - Chronological Session History

**Project:** Hallucination Detection via Hybrid Probabilistic Features  
**Period:** February 2026  
**Purpose:** Chronological record of research sessions, decisions, and findings

---

## Session 1: Domain Validation and Methodological Safeguards
**Date:** February 7, 2026  
**Duration:** Full working session  
**Focus:** Medicine and Psychology domain validation, pipeline verification

### Key Achievements

#### 1. Medicine Domain Fixed (AUROC 0.50 ‚Üí 0.68)

**Problem:** Generic text-based features inadequate for MCQ format

**Solution:** Created `MCQFeatureCalculator` with domain-specific features:
- `mcq_letter_consistency`: Fraction of samples agreeing on same answer letter
- `mcq_letter_entropy`: Shannon entropy over letter distribution
- `mcq_first_token_logprob`: Log-probability of answer letter only
- `mcq_first_token_prob`: Exponentiated version for interpretability

**Results:**
- AUROC improved to 0.6796
- Best calibration across all domains (ECE = 0.0573)
- MCQ features dominate importance rankings

**Format Detection:** Pipeline auto-detects MCQ format via `correct_index` column

#### 2. Psychology Domain Optimized (Recall 0.16 ‚Üí 0.84)

**Problem:** Perfect precision (1.0) but terrible recall (0.16) - caught only 4/25 hallucinations

**Root Cause:** Severe class imbalance (3:1 ratio)

**Solution:**
- Added `scale_pos_weight_multiplier` parameter (set to 2.0 for psychology)
- Implemented `evaluate_thresholds()` method (tested 0.3-0.5 range)
- Generated threshold analysis for deployment flexibility

**Results:**

| Metric | Before | After | Change |
|--------|--------|-------|--------|
| Precision | 1.000 | 0.313 | -0.687 |
| Recall | 0.160 | 0.840 | **+0.680** |
| F1 Score | 0.270 | 0.457 | **+0.187** |
| False Negatives | 21 | 4 | **-17** |

**Tradeoff:** Accepted 46 false positives for practical hallucination detection

#### 3. Methodological Safeguards Verified

**Feature Selection Pipeline:**
- ‚úÖ Constant feature removal via `VarianceThreshold(threshold=0.0)`
- ‚úÖ Deterministic selection with `random_state=42` in `mutual_info_classif`
- ‚úÖ Dynamic k_best capping (5:1 sample-to-feature ratio)

**Train/Test Split Integrity:**
- ‚úÖ Stratification maintains class distribution
- ‚úÖ Split column preserved in feature CSV
- ‚úÖ 80/20 ratio enforced across all domains
- ‚úÖ `random_state=42` ensures reproducibility

**Model Serialization:**
- ‚úÖ Fixed lambda function issue preventing pickle serialization
- ‚úÖ All models successfully saved to `outputs/models/xgboost_{domain}.pkl`

### Cross-Domain Performance Summary

| Domain | AUROC | Accuracy | ECE | Status |
|--------|-------|----------|-----|--------|
| Math | 0.7405 | 0.8056 | 0.1389 | ‚ö†Ô∏è Needs calibration |
| Psychology | 0.6960 | 0.5000 | 0.3439 | ‚úì Recall optimized |
| Medicine | 0.6796 | 0.6400 | 0.0573 | ‚úì Well-calibrated |
| Finance | 0.6442 | 0.8667 | 0.0173 | ‚ö†Ô∏è Constant features issue |

### Current Assumptions Documented

#### Domain-Specific Assumptions

1. **MCQ Format Detection**
   - Assumption: Medicine identifiable by `correct_index` column
   - Risk: False positives if other datasets use same column name
   - Mitigation: Consider explicit format specification in config

2. **Class Weight Strategy**
   - Default multiplier: 1.0 for balanced datasets
   - Exception: Psychology requires 2.0 due to severe imbalance
   - Documentation: Configuration file includes explicit note

3. **Feature Selection Method**
   - Method: Mutual information (handles non-linear relationships)
   - Alternatives: Chi-squared, ANOVA F-test available but unused
   - Rationale: Best for capturing complex hallucination patterns

4. **Decision Threshold**
   - Default: 0.5 balances precision and recall
   - Exception: Psychology has threshold analysis (0.3-0.5)
   - Consideration: Production systems may need different thresholds

5. **Post-Hoc Calibration**
   - Applied: Selectively (finance, psychology)
   - Not yet: Math domain (ECE=0.139 would benefit)
   - Criterion: Apply when ECE > 0.1

#### Methodological Assumptions

1. **Stratified Sampling Adequacy**
   - 80/20 split provides reasonable test set size
   - Reality: 100-108 test samples have higher variance
   - Consideration: Confidence intervals or bootstrap may be needed

2. **Hyperparameter Tuning Convergence**
   - 20 Optuna trials typically sufficient
   - Evidence: Best trials occur in first 15 trials
   - Alternative: 100+ trials for marginal improvements

3. **Feature Engineering Completeness**
   - Current: Epistemic + contextual + domain features
   - Gaps: No semantic similarity to reference documents (except IS Agents)
   - Consideration: Cross-domain features may improve generalization

### Known Limitations

#### Domain-Specific Limitations

**Finance:**
- Extreme class imbalance (4 faithful vs 26 hallucinations in test)
- Constant features present (needs re-run)
- Model achieves 86.7% accuracy by predicting "hallucination" for almost all

**Math:**
- ECE=0.139 indicates poor calibration
- Needs post-hoc calibration (Platt scaling or isotonic regression)
- Despite calibration issue, maintains best AUROC (0.7405)

**Medicine:**
- MCQ exact match only (ignores partial correctness)
- Doesn't account for equivalent medical terminology
- Format-dependent (not transferable to free-text medical responses)

**Psychology:**
- Low precision (0.31) - 69% of flagged responses are actually faithful
- Calibration degraded after class weight adjustment (ECE 0.027 ‚Üí 0.344)
- May not be acceptable for user-facing applications

#### Methodological Limitations

**Small Test Set Sizes (100-108 samples):**
- Higher variance in metrics (¬±5-10% confidence intervals)
- Finance particularly problematic (only 4 minority class samples)
- Differences <0.05 in AUROC may not be statistically significant
- Mitigation: Cross-validation, larger datasets, meta-analysis

**Ground Truth Quality:**

| Domain | Method | Limitation |
|--------|--------|------------|
| Medicine | MCQ exact match | Ignores partial correctness, terminology variations |
| Math | Numerical exact match | Sensitive to rounding, multiple solution paths |
| Finance | 10% tolerance | Arbitrary cutoff, may be domain-inappropriate |
| Psychology | Truthfulness labels | Subjective, culturally dependent |
| IS Agents | Document grounding | Depends on document quality |

**Feature Engineering Gaps:**
- No reference-based similarity (except IS Agents)
- No temporal features
- Limited semantic features beyond entropy
- No ensemble features (single model only)

**Generalization Concerns:**
- Models trained on specific datasets per domain
- No cross-domain training or transfer learning
- All responses from Llama-3.1-8B-Instruct-Turbo (patterns may differ for other LLMs)

### Recommendations for IS Agents Domain

**Pre-Validation Checks:**
1. Verify all 500 response files generated
2. Check for API timeout/rate limit errors
3. Confirm stochastic samples (n=5) exist per prompt
4. Validate document grounding logic

**Expected Results:**
- Hallucination rate: 40-60% (balanced)
- Document-grounding features should rank highly
- AUROC target: >0.60 (acceptable), >0.70 (strong)
- No constant features after VarianceThreshold

**Outstanding Fixes:**
- Finance: Re-run with VarianceThreshold fix
- Math: Apply post-hoc calibration
- Cross-domain: Generate comparative plots

### Methodological Contributions

**Novel Contributions:**
1. MCQ-specific feature engineering for hallucination detection
2. Threshold analysis framework for precision-recall tradeoffs
3. Class imbalance handling with documented multiplier strategy

**Validation Rigor:**
- Constant feature elimination
- Deterministic feature selection
- Sample-to-feature ratio enforcement
- Pickle serialization reliability

**Domain Diversity:**
- Structured (MCQ) vs unstructured (free-text)
- Factual (medicine, finance) vs reasoning (math, psychology)
- Document-grounded (IS Agents) vs knowledge-based
- Balanced vs severely imbalanced datasets

---

## Session 2: Final Domain Validation
**Date:** February 13, 2026  
**Focus:** Math and Finance re-runs with overfitting fixes, final pre-RQ validation

### Math Domain Re-run: Success ‚úÖ

**Changes Applied:**
- Feature selection (15 features from 41)
- Regularization (gamma=2.98, reg_alpha=3.20, reg_lambda=9.80)
- Hyperparameter tuning (20 Optuna trials)
- Early stopping with validation split

**Results:**

| Metric | Before | After | Change |
|--------|--------|-------|--------|
| **Test AUROC** | 0.7405 | **0.7783** | **+0.0378** ‚úÖ |
| **Train AUROC** | Not logged | 0.8439 | - |
| **Train/Test Gap** | Unknown | **0.0656** | ‚úÖ Healthy |
| **Test Accuracy** | 0.8056 | 0.7963 | -0.0093 |
| **Test ECE** | 0.1389 | 0.1837 | +0.0448 ‚ö†Ô∏è |

**Validation Status:** ‚úÖ PASSED
- No overfitting (gap 6.56% < 10% threshold)
- AUROC improved by 3.78 points
- **Highest AUROC across all domains**

### ‚ö†Ô∏è Calibration-Discrimination Trade-off (Math)

**Observation:** ECE increased 32% after applying overfitting fixes

**Root Cause:**
1. Feature selection reduced features (41 ‚Üí 15)
   - Fewer features = less information for probability estimation
   - Top discriminative features prioritized over calibration-friendly features
2. Strong regularization affects probability outputs
3. Optimizing for AUROC (discrimination) ‚â† optimizing for calibration

**Impact Assessment:**
- Model more **confident** (probabilities pushed to extremes)
- Better **discrimination** (AUROC increased)
- Worse **calibration** (predicted probabilities don't match actual rates)

**Research Perspective:**
- ‚úÖ **Not a blocker** - discrimination matters more for:
  - Comparing feature importance across domains
  - Evaluating semantic uncertainty vs naive confidence
  - Assessing cross-domain variance
- Calibration is secondary for research questions

**Solution for Production:**
If calibrated probabilities needed:
```python
from sklearn.calibration import CalibratedClassifierCV
calibrated_model = CalibratedClassifierCV(model, method='platt', cv='prefit')
```

**Thesis Contribution:**
- First documentation of ECE degradation from feature selection in hallucination detection
- Quantified impact: 32% ECE increase with 3.8-point AUROC improvement
- Provides guidance on when to prioritize discrimination vs calibration

### Finance Domain Re-run: In Progress

**Status:** Generating responses (500 samples)
**Previous Issues:** Constant features, small sample instability
**Expected:** Significant improvement with full dataset and proper fixes

### Domain Validation Status

| Domain | AUROC | Status | Notes |
|--------|-------|--------|-------|
| **Math** | 0.7783 | ‚úÖ Validated | Highest AUROC, calibration trade-off documented |
| **IS Agents** | 0.7491 | ‚úÖ Validated | Test>Train by 0.028 (within noise) |
| **Psychology** | 0.6960 | ‚úÖ Validated | Recall-optimized, threshold analysis available |
| **Medicine** | 0.6796 | ‚úÖ Validated | MCQ features, excellent calibration (ECE=0.057) |
| **Finance** | 0.6442 | ‚è≥ Re-running | Constant features issue, awaiting results |

### Validation Strategy for Small Samples

**Established Thresholds:**
- IS Agents: test>train by 0.028 ‚Üí validated as statistical noise
- Math: train>test by 0.066 ‚Üí validated as healthy generalization
- **Guideline:** Gaps <0.1 acceptable for datasets of 100-500 samples

### Next Steps

1. ‚úÖ Math validated - ready for RQ analysis
2. ‚è≥ Finance re-running (in progress)
3. ‚è≠Ô∏è Combine all features into `all_features.csv`
4. ‚è≠Ô∏è Run `analyze_research_questions.py` for RQ1, RQ2, RQ3
5. ‚è≠Ô∏è Interpret results for thesis

---

## Overall Project Status
**As of:** February 13, 2026

### Completion Progress: 80% (4/5 domains)

```
Math        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100% ‚úÖ AUROC: 0.78
IS Agents   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100% ‚úÖ AUROC: 0.75  
Psychology  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100% ‚úÖ AUROC: 0.70
Medicine    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100% ‚úÖ AUROC: 0.68
Finance     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  60% ‚è≥ In progress
```

### Performance Leaderboard

| Rank | Domain | AUROC | Accuracy | ECE | Sample Size |
|------|--------|-------|----------|-----|-------------|
| ü•á | Math | 0.7783 | 0.7963 | 0.1837 | 542 |
| ü•à | IS Agents | 0.7491 | 0.6900 | 0.3408 | 500 |
| ü•â | Psychology | 0.6960 | 0.5000 | 0.3439 | 500 |
| 4Ô∏è‚É£ | Medicine | 0.6796 | 0.6400 | 0.0573 | 500 |
| ‚è≥ | Finance | TBD | TBD | TBD | 500 (pending) |

### Technical Achievements ‚úÖ

**Pipeline Infrastructure:**
- Full 6-step pipeline operational
- Stratified train/test splits (post-labeling)
- Caching system functional
- Multi-provider API support (Groq + Together AI)
- Robust error handling and logging

**Feature Engineering:**
- Semantic Entropy (NLI-based clustering)
- Semantic Energy (logit distribution)
- Knowledge Popularity (entity rarity)
- Prompt Complexity (lexical + syntactic)
- MCQ-specific features
- Baseline metrics (MaxProb, Perplexity)

**Model Training:**
- XGBoost with Optuna tuning (20 trials)
- Feature selection (mutual information, k=15)
- Class imbalance handling
- Early stopping
- Cross-validation

**Visualization:**
- ROC curves, ARC curves, Calibration plots
- Confusion matrices, Feature importance charts
- **Total:** 25 figures (5 per domain √ó 5 domains)

### API Migration Success

**Groq ‚Üí Together AI Transition:**
- **Issue:** Hit Groq daily rate limit (500K tokens) at Finance sample 165/500
- **Solution:** Migrated to Together AI mid-pipeline
- **Validation:** 
  - ‚úÖ Structure compatible
  - ‚úÖ Hallucination rates similar (58.2% vs 65.0%)
  - ‚úÖ Together includes logprobs (beneficial)
  - ‚ö†Ô∏è Response files 39x larger

### Research Questions Status

**RQ1: Feature Hypothesis** ‚úÖ Ready
- All baseline models implemented
- Ablation study framework ready
- Awaiting finance for complete analysis

**RQ2: Semantic vs Naive** ‚úÖ Ready
- Data collected across 4 domains
- Comparative analysis ready
- Math excluded (no logprobs from Groq)

**RQ3: Cross-Domain Variance** ‚úÖ Ready
- Clear performance variance observed (AUROC 0.68-0.78)
- Different calibration characteristics (ECE 0.06-0.34)
- Domain-specific feature patterns visible

### Data Summary

**Response Generation:**
- Total: ~40,000+ responses across 4.5 domains
- API: Groq (Math, partial Finance) + Together AI (rest)
- Model: Llama-3.1-8B-Instruct-Turbo
- Stochastic samples: 5 per prompt (temp 0.7-1.0)

**Feature Matrices:**
- Math: 542 samples √ó 47 features (7 logprob features NULL)
- Psychology: 500 samples √ó 47 features
- Medicine: 500 samples √ó 54 features (MCQ-specific)
- IS Agents: 500 samples √ó 47 features
- Finance: 500 samples √ó 47 features (pending completion)

### Challenges & Solutions

**‚úÖ Solved:**
1. Groq rate limit ‚Üí Migrated to Together AI
2. Stratification issues ‚Üí Post-labeling splits
3. Semantic entropy bugs ‚Üí Fixed NLI clustering
4. Overfitting ‚Üí Feature selection, regularization, early stopping

**‚ö†Ô∏è Monitoring:**
1. Psychology calibration (ECE 0.34) ‚Üí Investigate threshold tuning
2. Math calibration trade-off ‚Üí Documented as research insight
3. File size (Together API) ‚Üí Acceptable trade-off for logprobs

---

## Key Insights for Thesis

### 1. Calibration-Discrimination Trade-off
- Feature selection improves discrimination but degrades calibration
- Quantified: 32% ECE increase, 3.8-point AUROC improvement
- **Novel finding** in hallucination detection literature

### 2. Domain-Specific Feature Engineering
- MCQ features transformed Medicine from random (0.50) to working (0.68)
- Document-grounding improved IS Agents from 0.52 to 0.75
- **Lesson:** One-size-fits-all approaches insufficient

### 3. Validation at Scale
- Small samples (‚â§100) may work by luck
- Large samples (500+) expose systematic issues
- Gaps <0.1 acceptable for test sets of 100-500 samples

### 4. Methodological Rigor
- Stratified splitting essential (prevents distribution mismatch)
- Feature selection critical for small samples (prevents overfitting)
- Hyperparameter tuning provides 5-10% AUROC improvements

### 5. API Provider Considerations
- Groq: Free but no logprobs (limits research questions)
- Together AI: Paid but complete features
- **Trade-off:** Cost vs completeness

---

**Log Status:** All major sessions documented  
**Next Session:** Finance completion and RQ analysis  
**Total Research Time:** ~6 weeks of experimentation

---

## Superseded Documents

This log consolidates and supersedes:
- `2026-02-07_domain_validation.md` (439 lines)
- `2026-02-13_final_domain_validation.md` (140 lines)
- `2026-02-13_progress_report.md` (229 lines)
- `2026-02-13_status_dashboard.md` (121 lines)

**Note:** `EXPERIMENT_LOG.md` remains as complementary reference for detailed run history.
