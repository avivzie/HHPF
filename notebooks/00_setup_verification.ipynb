{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHPF Setup Verification\n",
    "\n",
    "This notebook verifies that your environment is properly configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Core Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All core dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import xgboost\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"✅ All core dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Python Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.1 (v3.13.1:06714517797, Dec  3 2024, 14:00:22) [Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "✅ Python version is compatible\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "assert sys.version_info >= (3, 9), \"Python 3.9+ required\"\n",
    "print(\"✅ Python version is compatible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check PyTorch and MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0\n",
      "MPS available: True\n",
      "✅ GPU acceleration available (MPS)\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"✅ GPU acceleration available (MPS)\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"⚠️ Using CPU - this is fine for most operations\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load spaCy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy model loaded successfully\n",
      "Test entities extracted: [('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"✅ spaCy model loaded successfully\")\n",
    "    \n",
    "    # Test it\n",
    "    doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(f\"Test entities extracted: {entities}\")\n",
    "except:\n",
    "    print(\"❌ spaCy model not found. Run: python -m spacy download en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Together AI API key configured\n",
      "✅ Groq API key configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "together_key = os.getenv(\"TOGETHER_API_KEY\")\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if together_key and together_key != \"your_together_api_key_here\":\n",
    "    print(\"✅ Together AI API key configured\")\n",
    "else:\n",
    "    print(\"⚠️ Together AI API key not configured\")\n",
    "\n",
    "if groq_key and groq_key != \"your_groq_api_key_here\":\n",
    "    print(\"✅ Groq API key configured\")\n",
    "else:\n",
    "    print(\"⚠️ Groq API key not configured\")\n",
    "\n",
    "if not ((together_key and together_key != \"your_together_api_key_here\") or \n",
    "        (groq_key and groq_key != \"your_groq_api_key_here\")):\n",
    "    print(\"\\n❌ No API keys configured!\")\n",
    "    print(\"Edit .env file and add your API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load HHPF Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All configuration files loaded\n",
      "\n",
      "Datasets configured: ['medicine', 'math', 'finance', 'is_agents', 'psychology']\n",
      "Default Llama model: meta-llama/Llama-3-8b-chat-hf\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import load_config\n",
    "\n",
    "# Load configurations\n",
    "datasets_config = load_config('datasets')\n",
    "model_config = load_config('model')\n",
    "features_config = load_config('features')\n",
    "\n",
    "print(\"✅ All configuration files loaded\")\n",
    "print(f\"\\nDatasets configured: {list(datasets_config['datasets'].keys())}\")\n",
    "print(f\"Default Llama model: {model_config['llama']['default_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Transformers Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DeBERTa-v3-large (this may take a minute on first run)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478b2c6ca4654d24b2ba99d53ff297db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ae322edf8c4283a507ba50030d06bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129c67c6ff29411186e57d1784e69c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not extract SentencePiece model from /Users/aviv.gross/.cache/huggingface/hub/models--microsoft--deberta-v3-large/snapshots/64a8c8eab3e352a784c658aef62be1662607476f/spm.model using sentencepiece library due to \n",
      "SentencePieceExtractor requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\n",
      "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      ". Falling back to TikToken extractor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Could not load DeBERTa: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.\n",
      "This is needed for semantic entropy. Check your internet connection.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "print(\"Loading DeBERTa-v3-large (this may take a minute on first run)...\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "    # Note: We're not loading the full model here to save memory\n",
    "    print(\"✅ DeBERTa tokenizer loaded successfully\")\n",
    "    print(\"Note: Full model will be loaded when needed for semantic entropy\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not load DeBERTa: {e}\")\n",
    "    print(\"This is needed for semantic entropy. Check your internet connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  Setup Verification Complete\n",
      "============================================================\n",
      "\n",
      "✅ Your environment is ready for HHPF development!\n",
      "\n",
      "Next steps:\n",
      "1. Place your datasets in data/raw/\n",
      "2. Open 01_data_exploration.ipynb\n",
      "3. Start with a single domain (Math recommended)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"  Setup Verification Complete\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✅ Your environment is ready for HHPF development!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Place your datasets in data/raw/\")\n",
    "print(\"2. Open 01_data_exploration.ipynb\")\n",
    "print(\"3. Start with a single domain (Math recommended)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
